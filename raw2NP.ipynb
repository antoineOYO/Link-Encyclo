{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**goal is to trim 15 510 geographical articles, to charaterize each headphrase by the Geographical Entities (GE) mentionned in the article body**\n",
    "\n",
    "**Input :** `geobook_plain_23082024.pkl`\n",
    "\n",
    "**Output :** `geobook_23082024.pkl`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/antoine/Documents/GitHub/linkencyclo')\n",
    "datapath = '/home/antoine/Documents/GitHub/datas/'\n",
    "from stanza.models.common.doc import Span, Token\n",
    "\n",
    "from EncycloObject import Article, Book\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a `Book` instance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book with 15510 articles\n",
      "plain version of the geographical articles\n",
      "Attributes :\n",
      "dict_keys(['volume', 'numero', 'authors', 'text', 'hash', 'artfl', 'gold_coords', 'enccre', 'article_id', 'gold_qid', 'headphrase'])\n"
     ]
    }
   ],
   "source": [
    "with open(datapath+'geobook_plain_23082024.pkl', 'rb') as f:\n",
    "    plain_geobook = pickle.load(f)\n",
    "print(plain_geobook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the Article instance with hash `7/2925/GRENOBLE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://artflsrv04.uchicago.edu/philologic4.7/encyclopedie0922/navigate/7/2925',\n",
       " '7/2925/GRENOBLE',\n",
       " 'GRENOBLE, Gratianopolis, (Géogr.) ancienne ville de France, capitale du Dauphiné, avec un évêché suffragant de Vienne, & un parlement érigé en 1493 par Louis XI. qui n\\'étoit encore que dauphin ;  mais son pere ratifia cette érection deux ans après.\\nGrenoble est sur l\\'Isere, à onze lieues S O. de Chambéri, quarante-deux N. O. de Turin, seize S. E. de Vienne, cent vingt-quatre S. O. de Paris. Long. suivant Harris, 23d. 31\\'. 15\". suivant Cassini, 23d. 14\\'. 15\". latit 45d. 11\\'.\\nCette ville reçut le nom de Gratianopolis de l\\'empereur  Gratien fils de Valentinien I. car elle s\\'appelloit  auparavant Cularo ; & c\\'est sous ce nom qu\\'il en est parlé dans une lettre de Plancus à Cicéron, epist. xxiij. Long-tems après, les Romains l\\'érigerent en cité: dans le cinquieme siecle, elle fut assujettie par les Bourguignons, & dans le sixieme par les François Mérovingiens ; ensuite elle a obéi à Lothaire, à Boson, à Charles le Gros, à Louis l\\'Aveugle, à Rodolphe II. à Conrad & à Rodolphe le lâche, ses fils, qui lui donnerent de grands priviléges.\\nOn met au nombre des jurisconsultes dont Grenoble est la patrie, Pape (Guy), qui mourut en 1487 ; son recueil de décisions des plus belles questions de droit, n\\'est pas encore tombé dans l\\'oubli.\\nM. de Bouchenu de Valbonnais, (Jean Pierre Moret) premier président du parlement de Grenoble, né dans cette ville le 23 Juin 1651, mérite le titre du plus savant historiographe de son pays, par la belle histoire du Dauphiné, qu\\'il a publiée en trois vol. in fol. il est mort en 1730, âgé de 79 ans. Il voyagea dans sa jeunesse, & se trouva sur la flotte d\\'Angleterre à la bataille de Solbaye, la plus furieuse qu\\'eût encore  vû Ruyter, & où l\\'on s\\'attribua l\\'avantage de part & d\\'autre. (D. J.)')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grenoble = mybook._reach_article(headphrase='grenoble')\n",
    "grenoble.artfl, grenoble.hash, grenoble.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech parsing\n",
    "Stanza doc are stored in the `.parsed` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 11:44:31 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4b4456fd154c4c82aa4115f0428223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 11:44:31 INFO: Downloaded file to /home/antoine/stanza_resources/resources.json\n",
      "2024-08-23 11:44:32 INFO: Loading these models for language: fr (French):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2024-08-23 11:44:32 INFO: Using device: cpu\n",
      "2024-08-23 11:44:32 INFO: Loading: tokenize\n",
      "2024-08-23 11:44:32 INFO: Loading: mwt\n",
      "2024-08-23 11:44:32 INFO: Loading: pos\n",
      "2024-08-23 11:44:32 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "nlpstanza = stanza.Pipeline(lang='fr', processors='tokenize,mwt, pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in plain_geobook:\n",
    "    article.parsed = nlpstanza(article.text)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "We apply the BERT model to identify the GE mentionned in each article-body.\n",
    "\n",
    "From\n",
    "> 7/2925/GRENOBLE \n",
    "> \n",
    "> 'GRENOBLE, Gratianopolis, (Géogr.) ancienne ville de France, capitale du Dauphiné, avec un évêché suffragant de Vienne, ...'\n",
    "\n",
    "We want to store in the `article.ner` attribute the NER tags like :\n",
    "```python\n",
    "[\n",
    "    {'entity_group': 'NC_Spatial', 'score': 0.9601506, 'word': 'ancienne ville', 'start': 26, 'end': 40},\n",
    "    {'entity_group': 'NP_Spatial', 'score': 0.96639144, 'word': 'France', 'start': 44, 'end': 50},\n",
    "    {'entity_group': 'NC_Spatial', 'score': 0.96316826, 'word': 'capitale', 'start': 52, 'end': 60},\n",
    "    {'entity_group': 'NP_Spatial', 'score': 0.9662918, 'word': 'Dauphiné', 'start': 64, 'end': 72},\n",
    "    ...\n",
    "]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antoine/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/antoine/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "bert = pipeline(\"token-classification\", model=\"GEODE/bert-base-french-cased-edda-ner\",\n",
    "                aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in plain_geobook:\n",
    "    article.ner = article._apply_pipeline(bert)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add NER tags to the Stanza doc thanks to the method `Article._enrich_stanzadoc`\n",
    "- native `Token` instances of the Stanza doc receive the NER tags\n",
    "- native `Span` instances of the Stanza doc receive the contiguous merged NER tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in mybook:\n",
    "    article._enrich_stanzadoc()\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We search now for a pattern in the structure of the article-body :\n",
    "\n",
    "... NC_Spatial ... NP_Spatial ... NP_Spatial ...\n",
    "\n",
    "Strings are stored in the corresponding attributes : nc1, np1, np2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading stopwords from Solr\n",
    "with open('solr_stopwords.txt', 'r') as f:\n",
    "    stopwords = f.read().split('\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in mybook:\n",
    "    article._search_spatial_pattern(stopwords)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GE phrases are also normalized during the search for the pattern :\n",
    "- `ancienne ville` to `ville`\n",
    "- `royaume de France` to `france`\n",
    "- `St. Etienne` to `saint etienne`\n",
    "- \n",
    "The normalized strings are stored in `nps` (Proper Noun) and `ncs` (Common Noun) attributes :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France  |  france\n",
      "Dauphiné  |  dauphine\n",
      "Vienne  |  vienne\n",
      "Grenoble  |  grenoble\n",
      "l'Isere  |  isere\n",
      "Chambéri  |  chamberi\n",
      "Turin  |  turin\n",
      "Vienne  |  vienne\n",
      "Paris  |  paris\n",
      "Gratianopolis  |  gratianopolis\n",
      "Cularo  |  cularo\n",
      "Grenoble  |  grenoble\n",
      "Grenoble  |  grenoble\n",
      "Dauphiné  |  dauphine\n",
      "Angleterre  |  angleterre\n",
      "Solbaye  |  solbaye\n",
      "Ruyter  |  ruyter\n"
     ]
    }
   ],
   "source": [
    "for np in grenoble.nps:\n",
    "    print(np.text, ' | ', np.norm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ancienne ville  |  ville\n",
      "capitale  |  capitale\n",
      "un évêché suffragant  |  eveche\n",
      "Cette ville  |  ville\n",
      "cette ville  |  ville\n",
      "pays  |  pays\n"
     ]
    }
   ],
   "source": [
    "for nc in grenoble.ncs:\n",
    "    print(nc.text, ' | ', nc.norm_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the string normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_pairs = {} # pair (string, normalized string)\n",
    "nc_pairs = {} # pair (string, normalized string)\n",
    "for article in mybook:\n",
    "    for np in article.nps:\n",
    "        np_pairs[np.text] = np.norm_text\n",
    "    for nc in article.ncs:\n",
    "        nc_pairs[nc.text] = nc.norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------   NP\n",
      "('Narbata', 'narbata')\n",
      "('Meuze', 'meuze')\n",
      "('Autgard', 'autgard')\n",
      "('Sparte', 'sparte')\n",
      "('Ganesborough', 'ganesborough')\n",
      "('Amadabad', 'amadabad')\n",
      "('Aquitaines', 'aquitaines')\n",
      "('Lestrygoniae rupes', 'lestrygoniae')\n",
      "('Zambra', 'zambra')\n",
      "('Willonghby', 'willonghby')\n",
      "-------------------------------   NC\n",
      "('Sa cathédrale', 'cathedrale')\n",
      "('le promontoire', 'promontoire')\n",
      "('la contrée', 'contree')\n",
      "('les cavernes', 'cavernes')\n",
      "('long promontoire', 'promontoire')\n",
      "('ville vieille', 'ville')\n",
      "('états', 'etats')\n",
      "('un palais épiscopal', 'palais')\n",
      "('un évêché', 'eveche')\n",
      "('les terres', 'terres')\n"
     ]
    }
   ],
   "source": [
    "# print 20 random pairs\n",
    "import random\n",
    "print('-------------------------------   NP')\n",
    "for i in range(10):\n",
    "    print(random.choice(list(np_pairs.items())))\n",
    "print('-------------------------------   NC')\n",
    "for i in range(10):\n",
    "    print(random.choice(list(nc_pairs.items())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many articles do not have any NPs following the 1st NC ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([article for article in mybook if article.nc1_ and not article.np1_ and not article.np2_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Absolute count of NP-Spatial\n",
    "(Geographic Entities that are NP with a proper Noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybook._make_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('france', 2108),\n",
       " ('italie', 1575),\n",
       " ('allemagne', 1379),\n",
       " ('asie', 928),\n",
       " ('afrique', 890),\n",
       " ('espagne', 841),\n",
       " ('angleterre', 688),\n",
       " ('paris', 514),\n",
       " ('sicile', 423),\n",
       " ('rome', 419)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybook.nps_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ville', 12973),\n",
       " ('riviere', 3427),\n",
       " ('ile', 2957),\n",
       " ('pays', 2867),\n",
       " ('mer', 2514),\n",
       " ('province', 2334),\n",
       " ('royaume', 1913),\n",
       " ('capitale', 1763),\n",
       " ('cote', 1328),\n",
       " ('fleuve', 1178)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybook.ncs_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re order NP1 and NP2\n",
    "When defining the HEADPHRASE, the authors can mention NP1 and NP2 in the article-body. They will help us querying our Knowledge Base by re-framing the search : we will limit the search to an area defined by NP1, or NP2, or the two.\n",
    "\n",
    "Hypothesis : the more a NP is quoted in the corpus, the higher the probabilities are that it's a big geographical entity, possibly containing the other NP mentionned int the corpus.\n",
    "\n",
    "We therefore characterize each NP by its absolute count in the corpus, and redefine these 2 attributes :\n",
    "- NP1* is the least quoted entity between NP1 and NP2\n",
    "- NP2* is the most quoted entity between NP1 and NP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in mybook:\n",
    "    if not article.np2_:\n",
    "        np1_star = article.np1_\n",
    "        np2_star = None\n",
    "    elif mybook.nps_counter[article.np1_] < mybook.nps_counter[article.np2_] :\n",
    "        np1_star = article.np1_\n",
    "        np2_star = article.np2_\n",
    "    else:\n",
    "        np1_star = article.np2_\n",
    "        np2_star = article.np1_\n",
    "    \n",
    "    article.np1_star = np1_star\n",
    "    article.np2_star = np2_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the reordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lothian ecosse meridionale\n",
      "gaster suisse\n",
      "iraque arabiquel chaldee\n",
      "tirol allemagne\n",
      "japon None\n",
      "paris france\n",
      "treves allemagne\n",
      "jascartes sihon\n",
      "brabant hollandois pays bas\n",
      "cetina dalmatie\n",
      "samnis samnium\n",
      "sarmatie europe\n",
      "croatie save\n",
      "ruse mingrelie\n",
      "carnie italie\n",
      "provence france\n",
      "thessalonique macedoine\n",
      "istrie rome\n",
      "mogol indes\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "for article in mybook._sample(20):\n",
    "    print(article.np1_star, article.np2_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Book with 15510 articles\n",
       "version with POS tags, enriched Stanza Spans with NER tags and spatial patterns, and with reordered NP1* and NP2*\n",
       "Attributes :\n",
       "dict_keys(['volume', 'numero', 'authors', 'text', 'hash', 'artfl', 'gold_coords', 'enccre', 'article_id', 'gold_qid', 'parsed', 'ner', 'nc1', 'nc1_', 'np1', 'np1_', 'np2', 'np2_', 'ncs', 'nps', 'headphrase', 'np1_star', 'np2_star'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybook.description  = 'version with POS tags, enriched Stanza Spans with NER tags'\n",
    "mybook.description += '\\nand spatial patterns, and with reordered NP1* and NP2*'\n",
    "with open(datapath+'geobook_26082024.pkl', 'wb') as f:\n",
    "    pickle.dump(mybook, f)\n",
    "mybook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
